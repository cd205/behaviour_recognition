{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/laggui/pymultiprocessing-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue, Pipe\n",
    "\n",
    "# Pipe for two-way communication only. Should be faster.\n",
    "# Queue is a process - and thread - safe implementation with an underlying Pipe\n",
    "\n",
    "def plot_detections(connection_obj):\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            data = connection_obj.recv()\n",
    "            if i == 0:\n",
    "                # initialize figure on first message received\n",
    "                img_size = data\n",
    "                background = np.ones((img_size[0], img_size[1], img_size[2]), dtype=np.uint8) * 255\n",
    "                fig = plt.figure()\n",
    "                disp = plt.imshow(background)\n",
    "                plt.ion()\n",
    "            else:\n",
    "                if isinstance(data, str) and data == \"END\":\n",
    "                    print('Last message received')\n",
    "                    break\n",
    "                overlay = np.ones((img_size[0], img_size[1], img_size[2]), dtype=np.uint8) * 255\n",
    "                #print(data)\n",
    "                [cv2.rectangle(overlay,(x,y),(x+w,y+h),(0,0,255),2) for (x,y,w,h) in data]\n",
    "                disp.set_data(overlay)\n",
    "                plt.pause(0.001)\n",
    "            i = i + 1\n",
    "        except EOFError:\n",
    "            print('Communication end')\n",
    "            break\n",
    "    \n",
    "    print('Closing matplotlib')\n",
    "    if plt.fignum_exists(fig.number):\n",
    "        plt.close(fig)\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "    plt.close('all')\n",
    "\n",
    "def cam_output_face_detect(connection_obj, flip=True, haar_frontal='data/haarcascade_frontalface_default.xml', haar_second=None):\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "    # init cam\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    # capture first frame\n",
    "    ret, frame = cam.read()\n",
    "    h, w, c = frame.shape\n",
    "    \n",
    "    # first send the height and width of image\n",
    "    connection_obj.send([h, w, c])\n",
    "\n",
    "    # initialize figure\n",
    "    fig = plt.figure()\n",
    "    disp = plt.imshow(frame)\n",
    "    plt.ion()\n",
    "\n",
    "    frontal_cascade = cv2.CascadeClassifier(haar_frontal)\n",
    "    if haar_second:\n",
    "        second_cascade = cv2.CascadeClassifier(haar_second)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if flip:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = frontal_cascade.detectMultiScale(gray, 1.05, 6)\n",
    "        connection_obj.send(faces)\n",
    "        [cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2) for (x,y,w,h) in faces]\n",
    "        # if haar_second:\n",
    "        #     second_faces = second_cascade.detectMultiScale(gray, 1.05, 6)\n",
    "        #     [cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2) for (x,y,w,h) in second_faces]\n",
    "        disp.set_data(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.pause(0.001)\n",
    "        if not plt.fignum_exists(fig.number):\n",
    "            break\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "    plt.close('all')\n",
    "    connection_obj.send(\"END\")\n",
    "    connection_obj.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#haar_profile = 'data/haarcascade_profileface.xml'\n",
    "# create pipe\n",
    "recv_conn, send_conn = Pipe(duplex=False)\n",
    "\n",
    "# create new processes\n",
    "proc_1 = Process(target=cam_output_face_detect, args=(send_conn,))\n",
    "proc_2 = Process(target=plot_detections, args=(recv_conn,))\n",
    "\n",
    "# run processes\n",
    "proc_1.start()\n",
    "proc_2.start()\n",
    "\n",
    "# wait until processes finish\n",
    "proc_1.join()\n",
    "proc_2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "def get():\n",
    "        global cap\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        return cap\n",
    "\n",
    "def video(cap):\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        return frame\n",
    "\n",
    "\n",
    "p1 = multiprocessing.Process(target = get)\n",
    "p1.start()\n",
    "p1.join()\n",
    "\n",
    "while True:\n",
    "    frame = video(cap)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 5 6]\n",
      "[5 5]\n",
      "[0 6 7 4 1 2 3 6 8]\n",
      "[]\n",
      "[4 5 8 5 6 7 8 1]\n",
      "[]\n",
      "[8 1 8]\n",
      "[1 2]\n",
      "[2]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time \n",
    "\n",
    "\n",
    "def func_run_forever():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def func_run_once():\n",
    "    n=0\n",
    "    while n<10:\n",
    "        val = np.random.randint(10,size=np.random.randint(10))\n",
    "        print(val)\n",
    "        time.sleep(0.25)\n",
    "        n += 1\n",
    "\n",
    "\n",
    "p1 = Thread(target=func_run_forever, name=\"n1\")\n",
    "p2 = Thread(target=func_run_once, name=\"n2\")\n",
    "p1.start()\n",
    "p2.start()\n",
    "p1.join()\n",
    "p2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('computer_vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0777b629fee9d2d81ecef945347a78c44178a54bd3f588c64ea08ff012c2b82a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
