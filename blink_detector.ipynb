{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import importlib\n",
    "import math\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmark detection function \n",
    "def landmarksDetection(img, results, draw=False):\n",
    "    img_height, img_width= img.shape[:2]\n",
    "    # list[(x,y), (x,y)....]\n",
    "    mesh_coord = [(int(point.x * img_width), int(point.y * img_height)) for point in results.multi_face_landmarks[0].landmark]\n",
    "    if draw :\n",
    "        [cv.circle(img, p, 2, utils.GREEN, -1) for p in mesh_coord]\n",
    "\n",
    "    # returning the list of tuples for each landmarks \n",
    "    return mesh_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face bounder indices \n",
    "FACE_OVAL=[ 10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103,67, 109]\n",
    "\n",
    "# lips indices for Landmarks\n",
    "LIPS=[ 61, 146, 91, 181, 84, 17, 314, 405, 321, 375,291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95,185, 40, 39, 37,0 ,267 ,269 ,270 ,409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78 ]\n",
    "LOWER_LIPS =[61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "UPPER_LIPS=[ 185, 40, 39, 37,0 ,267 ,269 ,270 ,409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78] \n",
    "# Left eyes indices \n",
    "LEFT_EYE =[ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]\n",
    "LEFT_EYEBROW =[ 336, 296, 334, 293, 300, 276, 283, 282, 295, 285 ]\n",
    "\n",
    "# right eyes indices\n",
    "RIGHT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ]  \n",
    "RIGHT_EYEBROW=[ 70, 63, 105, 66, 107, 55, 65, 52, 53, 46 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to cam\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1, \n",
    "    refine_landmarks=True, \n",
    "    min_detection_confidence=0.5, \n",
    "    min_tracking_confidence=0.5\n",
    ") as face_mesh:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Show image\n",
    "        frame = cv.flip(frame, 1)\n",
    "        rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        img_height, img_width = frame.shape[:2]   # This is the actual measurements of the frame size.  We'll use this to multiply by the normalised x,y coordinates from results.multi_face_landmarks\n",
    "        results = face_mesh.process(rgb_frame)\n",
    "        if results.multi_face_landmarks:\n",
    "            mesh_coords = landmarksDetection(frame, results, False)\n",
    "            #print(mesh_coords[p] for p in RIGHT_EYE)\n",
    "            frame = utils.fillPolyTrans(frame, [mesh_coords[p] for p in RIGHT_EYE], utils.GREEN, opacity=0.5)\n",
    "            frame = utils.fillPolyTrans(frame, [mesh_coords[p] for p in LEFT_EYE], utils.GREEN, opacity=0.5)\n",
    "            frame = utils.fillPolyTrans(frame, [mesh_coords[p] for p in RIGHT_EYEBROW], utils.RED, opacity=0.5)\n",
    "            frame = utils.fillPolyTrans(frame, [mesh_coords[p] for p in LEFT_EYEBROW], utils.RED, opacity=0.5)\n",
    "            frame = utils.fillPolyTrans(frame, [mesh_coords[p] for p in LOWER_LIPS], utils.PINK, opacity=0.5)\n",
    "            frame = utils.fillPolyTrans(frame, [mesh_coords[p] for p in UPPER_LIPS], utils.PINK, opacity=0.5)\n",
    "            frame = utils.fillPolyTrans(frame, [mesh_coords[p] for p in FACE_OVAL], utils.GRAY, opacity=0.1)\n",
    "\n",
    "        cv.imshow('Webcam', frame)\n",
    "\n",
    "        # check if any keys are being pressed, if this is 'q' break out of while loop and release webcam & close frame\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blink calculator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclaideanDistance(point, point1):\n",
    "    x, y = point \n",
    "    x1, y1 = point1\n",
    "    distance = math.sqrt((x1-x)**2 + (y1-y)**2)\n",
    "    return distance \n",
    "\n",
    "def blinkRatio(img, landmarks, right_indices, left_indices):\n",
    "    # Right eye\n",
    "    # horizontal line\n",
    "    rh_right = landmarks[right_indices[0]]\n",
    "    rh_left = landmarks[right_indices[8]]\n",
    "    # vertical line\n",
    "    rv_top = landmarks[right_indices[12]]\n",
    "    rv_bottom = landmarks[right_indices[4]]\n",
    "\n",
    "    cv.line(frame, rh_right, rh_left, utils.GREEN, 2)\n",
    "    cv.line(frame, rv_top, rv_bottom, utils.GREEN, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to cam\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1, \n",
    "    refine_landmarks=True, \n",
    "    min_detection_confidence=0.5, \n",
    "    min_tracking_confidence=0.5\n",
    ") as face_mesh:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Show image\n",
    "        frame = cv.flip(frame, 1)\n",
    "        rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        img_height, img_width = frame.shape[:2]   # This is the actual measurements of the frame size.  We'll use this to multiply by the normalised x,y coordinates from results.multi_face_landmarks\n",
    "        results = face_mesh.process(rgb_frame)\n",
    "        if results.multi_face_landmarks:\n",
    "            mesh_coords = landmarksDetection(frame, results, False)\n",
    "            #print(mesh_coords[p] for p in RIGHT_EYE)\n",
    "            blinkRatio(frame, mesh_coords, RIGHT_EYE, LEFT_EYE)\n",
    "\n",
    "        cv.imshow('Webcam', frame)\n",
    "\n",
    "        # check if any keys are being pressed, if this is 'q' break out of while loop and release webcam & close frame\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('computer_vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0777b629fee9d2d81ecef945347a78c44178a54bd3f588c64ea08ff012c2b82a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
